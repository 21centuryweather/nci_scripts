#!/g/data3/hh5/public/apps/miniconda3/envs/analysis3-20.01/bin/python

import pandas
import subprocess
import json
import argparse
import re
import sys

def decode_bytes(s):
    if pandas.isnull(s):
        return s

    scales = {
        'k': 1024,
        }
    if not s.endswith('b'):
        raise Exception(f"{s} doesn't look like a size")

    scale = 1
    s = s[:-1]

    if not s[-1].isdigit():
        scale = scales[s[-1]]
        s = s[:-1]

    return int(s) * scale


def maybe_get(x, key):
    if pandas.isnull(x):
        return x
    else:
        return x[key]


def clean_qstat_json(stream):
    """
    Clean up the improperly escaped JSON returned by qstat
    """
    string_entry_re = re.compile(r'^\s*"(?P<key>.+)":"(?P<value>.+)"(?P<comma>,?)$')

    lines = []

    for line in stream.splitlines():
        match = string_entry_re.match(line)
        if match is not None:
            fixed_value = match.group('value').replace('"', '\\"')
            line = f'"{match.group("key")}":"{fixed_value}"{match.group("comma")}'

        lines.append(line)

    return json.loads(''.join(lines))

description = """
Print more detailed information from qstat

Returns the following columns for each job:
    project:    NCI project the job was submitted under
    job_name:   Name of the job
    queue:      Queue the job was submitted to
    state:      Current state - 'Q' in queue, 'R' running, 'H' held, 'E' finished
    ncpus:      Number of cpus requested
    walltime:   Walltime the job has run for so far
    su:         SU cost of the job so far
    mem_pct:    Percent of the memory request used
    cpu_pct:    Percent of time CPUs have been active
    qtime:      Time the job spent in the queue before starting

If 'mem_pct' is below 80% make sure you're not requesting too much memory (4GB
per CPU or less is fine)

If 'cpu_pct' is below 80% and you're requesting more than one CPU make sure
your job is making proper use of parallelisation
"""

def main():
    parser = argparse.ArgumentParser(description=description, formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--historical','-x', help='Show historical info', action='store_true')
    parser.add_argument('--format','-f', help='Output format', choices=['table','csv','json'], default='table')
    args = parser.parse_args()

    command= ['/opt/pbs/default/bin/qstat','-f','-F','json']

    if args.historical:
        command.append('-x')

    r = subprocess.run(command, stdout=subprocess.PIPE, universal_newlines=True)
    r.check_returncode()

    j = clean_qstat_json(r.stdout)

    if 'Jobs' not in j:
        return

    df = pandas.DataFrame.from_dict(j['Jobs'], orient='index')

    df['resources_used'] = df.get('resources_used', pandas.Series(index=df.index, dtype='object'))
    df['stime'] = df.get('stime', pandas.Series(index=df.index, dtype='datetime64[ns]'))

    df['ncpus'] = df['Resource_List'].apply(maybe_get,key='ncpus')
    df['cputime'] = pandas.to_timedelta(df['resources_used'].apply(maybe_get,key='cput'))
    df['walltime'] = pandas.to_timedelta(df['resources_used'].apply(maybe_get,key='walltime'))
    df['mem_used'] = df['resources_used'].apply(lambda x: decode_bytes(maybe_get(x, 'mem')))
    df['mem_request'] = df['Resource_List'].apply(lambda x: decode_bytes(x['mem']))
    df['mem_pct'] = df['mem_used'] / df['mem_request'] * 100
    df['cpu_pct'] = df['cputime'] / df['walltime'] / df['ncpus'] * 100
    df['state'] = df['job_state']
    df['stime'] = pandas.to_datetime(df['stime']).fillna(pandas.Timestamp.now())
    df['qtime'] = (df['stime'] - pandas.to_datetime(df['qtime'])).apply(lambda x: x.round('min'))
    df['wall_hours'] = pandas.to_timedelta(df['walltime']).apply(lambda x: x.total_seconds()) / (60*60)

    # The number of cpus this would use based on the memory request
    queue_mem = {'hugemem-exec': 32}
    df['ncpus_by_mem'] = df['mem_request'] / (df['queue'].apply(lambda x: queue_mem.get(x, 4)) * 1024**3)

    # Multiply the larger of ncpus, ncpus_by_mem by the walltime
    df['su'] = df['ncpus'].where(df['ncpus'] > df['ncpus_by_mem'], df['ncpus_by_mem']) * df['wall_hours']

    queue_scale = {'express-exec': 6, 'hugemem-exec': 3}
    df['su'] = df['su'] * df['queue'].apply(lambda x: queue_scale.get(x, 2))

    table =  df[['project','Job_Name','queue','state','ncpus','walltime','su','mem_pct', 'cpu_pct', 'qtime']]

    if args.format == 'table':
        pct_format = lambda x: f'{x:.0f}%'
        round_format = lambda x: f'{x:.0f}'
        table.to_string(sys.stdout, formatters={'su': round_format, 'mem_pct': pct_format, 'cpu_pct': pct_format})
        print()
    elif args.format == 'csv':
        table.to_csv(sys.stdout, index_label='jobid')
    elif args.format == 'json':
        table.to_json(sys.stdout, orient='index', indent=4, date_unit='s')
    else:
        raise NotImplementedError

if __name__ == '__main__':
    main()
